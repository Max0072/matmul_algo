# Почему Winograd быстрый, а Strassen медленный?

## TL;DR (Короткий ответ)

**Winograd побеждает потому что:**
- ✅ Простая структура: всего 8 скаляров временной памяти
- ✅ Линейный доступ к памяти (хорошо для кэша)
- ✅ Легко векторизуется компилятором
- ✅ Мало вызовов функций

**Strassen проигрывает потому что:**
- ❌ 16 временных матриц 2×2 (512 байт)
- ❌ Много вызовов функций (add_2x2, sub_2x2, mul_naive_2x2)
- ❌ Фрагментированный доступ к памяти
- ❌ Сложнее для компилятора оптимизировать

---

## 1. Сравнение Operation Counts

### Измеренные значения (4×4):

```
Algorithm        Multiplications   Additions   Total Ops   Temp Memory
────────────────────────────────────────────────────────────────────────
Naive                   64             64          128         0 bytes
Winograd               48            128          176         64 bytes (8 doubles)
Strassen 4×4           56            128          184         512 bytes (16 matrices 2×2)
```

### Проблема Strassen:

**Umножений меньше, но НЕ намного:**
- Winograd: 48 mul vs 64 naive = **-25% умножений**
- Strassen: 56 mul vs 64 naive = **-12.5% умножений**

**Почему только 56 умножений?**
Strassen 4×4 делает 7 умножений 2×2 блоков:
- 7 × (2×2 naive) = 7 × 8 = **56 умножений**
- Это НЕ настоящий Strassen! Настоящий Strassen дает 49 умножений только при рекурсии до 1×1

---

## 2. Анализ памяти и cache behavior

### Winograd 4×4 - минималистичный подход:

```cpp
// Временная память: всего 8 doubles (64 байта)
T p[4];  // 4 doubles = 32 bytes
T q[4];  // 4 doubles = 32 bytes
// ИТОГО: 64 байта - помещается в 1 cache line!

// Препроцессинг - последовательный доступ
for (int i = 0; i < 4; i++)
    p[i] = -A(i,0)*A(i,1) - A(i,2)*A(i,3);  // читаем A построчно

for (int j = 0; j < 4; j++)
    q[j] = -B(0,j)*B(1,j) - B(2,j)*B(3,j);  // читаем B по столбцам

// Основной цикл - предсказуемый паттерн доступа
for (int i = 0; i < 4; i++) {
    for (int j = 0; j < 4; j++) {
        // Используем уже вычисленные p[i] и q[j]
        // Прямой доступ к элементам A и B
        C(i,j) = p[i] + q[j] +
                 (A(i,0)+B(1,j))*(A(i,1)+B(0,j)) +
                 (A(i,2)+B(3,j))*(A(i,3)+B(2,j));
    }
}
```

**Преимущества:**
1. Маленькая временная память → весь рабочий набор в L1 кэше
2. Простые циклы → компилятор легко векторизует
3. Все операции inline → нет вызовов функций
4. Предсказуемые паттерны доступа → prefetcher работает хорошо

### Strassen 4×4 - тяжеловесный подход:

```cpp
// Временная память: 16 матриц по 4 элемента = 512 байт
Matrix<T> S1(2,2), S2(2,2), S3(2,2), S4(2,2), S5(2,2), S6(2,2), S7(2,2);
Matrix<T> P1(2,2), P2(2,2), P3(2,2), P4(2,2), P5(2,2), P6(2,2), P7(2,2);
Matrix<T> T1(2,2), T2(2,2);

// Каждая Matrix<T>(2,2) делает:
//   1. Аллокацию std::vector<T>(4)
//   2. Возможно dynamic memory allocation (зависит от std::vector)
//   3. Инициализацию всех элементов нулями

// Вызовы функций - много overhead
sub_2x2(B12, B22, view(S1), cnt);     // вызов функции
mul_naive_2x2(A11, view(S1), view(P1), cnt);  // еще вызов

// Внутри mul_naive_2x2 - тройной вложенный цикл с индирекцией:
for(int i = 0; i < 2; i++) {
    for(int j = 0; j < 2; j++) {
        T sum = T{};
        for(int k = 0; k < 2; k++) {
            // A и B это MatrixView с индирекцией через stride
            sum = add(sum, mul(A(i,k), B(k,j), cnt), cnt);
        }
        C(i,j) = sum;
    }
}
```

**Проблемы:**
1. **512 байт временной памяти** - не помещается в 1-2 cache lines
2. **16 аллокаций Matrix<T>** - malloc overhead (даже если small vector optimization)
3. **Много вызовов функций** (add_2x2, sub_2x2, mul_naive_2x2 × 7 раз)
4. **MatrixView индирекция** - доступ через ptr + stride*i + j
5. **Фрагментированный доступ** - прыгаем между S1, S2, P1, P2, T1, T2

---

## 3. Compiler optimization perspective

### Что видит компилятор в Winograd:

```cpp
// Простой код с inline операциями
for (int i = 0; i < 4; i++) {
    for (int j = 0; j < 4; j++) {
        double a0 = A(i,0), a1 = A(i,1), a2 = A(i,2), a3 = A(i,3);
        double b0 = B(0,j), b1 = B(1,j), b2 = B(2,j), b3 = B(3,j);

        C(i,j) = p[i] + q[j] +
                 (a0 + b1) * (a1 + b0) +
                 (a2 + b3) * (a3 + b2);
    }
}
```

**Компилятор может:**
- ✅ Unroll внутренний цикл (всего 4 итерации)
- ✅ Vectorize (SIMD) - обработать 4 элемента сразу
- ✅ Register allocation - держать переменные в регистрах
- ✅ FMA (Fused Multiply-Add) - `a*b+c` за 1 инструкцию
- ✅ Prefetch - загружать данные заранее

### Что видит компилятор в Strassen:

```cpp
// Множество вызовов функций
sub_2x2(B12, B22, view(S1), cnt);
mul_naive_2x2(A11, view(S1), view(P1), cnt);
// ... еще 10+ вызовов функций

// Внутри каждой функции - непрозрачные операции
template <class T, class U, class V>
inline void mul_naive_2x2(U A, V B, MatrixView<T> C, OpCounter* cnt) {
    // Тройной цикл с индирекцией
    for(int i = 0; i < 2; i++)
        for(int j = 0; j < 2; j++)
            for(int k = 0; k < 2; k++)
                C(i,j) = add(C(i,j), mul(A(i,k), B(k,j), cnt), cnt);
}
```

**Компилятор НЕ может:**
- ❌ Легко inline все вызовы (слишком глубоко)
- ❌ Vectorize (слишком много indirection)
- ❌ Оптимизировать между вызовами функций
- ❌ Убрать OpCounter overhead (передается везде)
- ❌ Оптимизировать MatrixView индирекцию

---

## 4. Реальные измерения производительности

### Benchmark результаты (256×256, double):

```
Algorithm               Time (ms)    vs Naive    Explanation
─────────────────────────────────────────────────────────────────
naive                   59-64        baseline    Simple, компилятор хорошо оптимизирует
blocked_winograd        53-55        -10% ✓      Cache-friendly + меньше умножений
strassen (recursive)    68-75        +13% ✗      Рекурсия + overhead
blocked_naive           69-76        +15% ✗      Overhead блоков
blocked_strassen        128-129      +100% ✗✗    Двойной overhead!
```

### Почему blocked_strassen так медленный (2x медленнее naive)?

**Двойной overhead:**
1. **Overhead блоков (blocked multiply):**
   - Для 256×256: (256/4)² = 4096 блоков
   - Для каждого блока: создание temp_result(4,4)
   - 4096 аллокаций + копирований!

2. **Overhead Strassen внутри блока:**
   - Каждый блок 4×4 создает 16 матриц 2×2
   - 4096 блоков × 16 матриц = **65536 аллокаций** Matrix<T>(2,2)!
   - Плюс все вызовы функций

**Результат:** blocked_strassen тратит больше времени на overhead, чем экономит на умножениях!

---

## 5. Детальное сравнение для blocked алгоритмов (256×256)

### Blocked Winograd - эффективный:

```
Размер: 256×256
Блоки: (256/4)² = 4096 блоков

Для каждого блока 4×4:
  1. Создать temp_result(4,4)          ← 1 аллокация
  2. Вызвать kernel_winograd_4x4       ← 1 вызов функции
     - Внутри: простой код с 8 скалярами
     - Все inline, хороший cache locality
  3. Добавить результат к C            ← 16 сложений

Итого на 4096 блоков:
  - 4096 аллокаций Matrix<T>(4,4)
  - 4096 вызовов kernel_winograd (простая функция)
  - Хороший cache behavior

Время: 53-55 ms ✓
```

### Blocked Strassen - неэффективный:

```
Размер: 256×256
Блоки: (256/4)² = 4096 блоков

Для каждого блока 4×4:
  1. Создать temp_result(4,4)          ← 1 аллокация
  2. Вызвать kernel_strassen_4x4       ← 1 вызов функции
     - Внутри kernel_strassen_4x4:
       * Создать 16 матриц 2×2         ← 16 аллокаций!
       * 7 вызовов mul_naive_2x2       ← 7 вызовов
       * Много вызовов add_2x2/sub_2x2 ← еще вызовы
  3. Добавить результат к C            ← 16 сложений

Итого на 4096 блоков:
  - 4096 × (1 + 16) = 69632 аллокаций!
  - 4096 × (1 + 7 + N) = десятки тысяч вызовов функций
  - Плохой cache behavior (прыжки между матрицами)

Время: 128-129 ms ✗ (в 2x медленнее!)
```

---

## 6. Почему Winograd экономит больше умножений?

### Теоретическое сравнение:

```
Naive 4×4:          n³ = 64 умножений

Winograd 4×4:       48 умножений
  Экономия:         64 - 48 = 16 (-25%)

Strassen 4×4:       7 × 8 = 56 умножений
  (7 умножений 2×2 блоков, каждое 2³=8 умножений)
  Экономия:         64 - 56 = 8 (-12.5%)
```

**Почему так мало в Strassen 4×4?**

Настоящий Strassen экономит умножения через рекурсию:
- 1 уровень рекурсии: 7 умножений вместо 8
- 2 уровня рекурсии: 7² = 49 умножений вместо 8² = 64
- k уровней: 7^k умножений вместо 8^k

Но для 4×4 с базовым случаем 2×2:
- Всего 1 уровень рекурсии
- 7 умножений 2×2 = 7 × 8 = 56 умножений
- Экономия всего 8 умножений!

**Winograd не рекурсивный**, но имеет специальную формулу которая напрямую уменьшает умножения.

---

## 7. Итоговые выводы

### Почему Winograd быстрый:

1. **Минимальный overhead:**
   - 8 скаляров временной памяти (64 байта)
   - Нет аллокаций, нет вызовов функций
   - Все inline

2. **Хороший для hardware:**
   - Весь рабочий набор в L1 кэше
   - Предсказуемые паттерны доступа
   - Легко векторизуется компилятором

3. **Хорошая экономия умножений:**
   - -25% умножений (48 вместо 64)
   - Это существенно для дорогих FP операций

4. **Масштабируется хорошо:**
   - Blocked Winograd: простое умножение блоков
   - Мало overhead на блок

### Почему Strassen медленный:

1. **Огромный overhead:**
   - 512 байт временной памяти на каждый блок 4×4
   - 16 аллокаций Matrix<T>(2,2)
   - Множество вызовов функций

2. **Плохой для hardware:**
   - Фрагментированный доступ к памяти
   - Прыжки между временными матрицами
   - Сложно для compiler optimization

3. **Маленькая экономия умножений:**
   - Всего -12.5% умножений (56 вместо 64)
   - Не компенсирует overhead

4. **Катастрофа при масштабировании:**
   - Blocked Strassen: 16× аллокаций на блок
   - Overhead растет квадратично!

### Когда Strassen может быть полезен:

- **Очень большие матрицы** (n > 2000-4000)
- **Глубокая рекурсия** (много уровней)
- **Специализированная реализация** без overhead
- **Когда умножения ОЧЕНЬ дорогие** (символьные вычисления, большие числа)

Для практических размеров (n < 1000) на современном железе:
- **Naive с -O2 оптимизацией** - хорош
- **Blocked Winograd** - ЛУЧШИЙ (10-15% быстрее)
- **Strassen** - медленнее из-за overhead

---

## Практический вывод

**Для production кода используйте:**
1. BLAS библиотеки (Intel MKL, OpenBLAS) - в 10-100x быстрее
2. Blocked Winograd - если нельзя использовать BLAS
3. Naive с -O2 - простой и эффективный baseline

**НЕ используйте Strassen** на практических размерах, если только:
- Вы не пишете специализированную реализацию без overhead
- Матрицы не огромные (n > 5000)
- У вас нет времени на оптимизацию
